## Zillow Zestimate® Improvement

### Overview
Imagine being able to determine the value of your home without outside help, and in only a few clicks. That's what Zestimate® does: it provides users with an independent, unbiased starting point for determining a home’s worth based on data from over 100 million other homes on and off the market. Through Kaggle— the world's largest platform for predictive analytics competitions— Zillow challenged the global data science community to improve the accuracy of the tool. I joined the contest as a solo participant, motivated by using data science/digital engineering to solve a real world problem.

### Problem
The earliest Zestimates from 2006 had error rates of roughly 14%, were calculated monthly, and for only about half of the homes in the country. Today, the error rates are down to about 5%, are calculated continually and for all homes nationwide. Zillow wants to continue to close the gap in the margin of error, thereby enhancing the accuracy of the client-facing Zestimate tool.

### Process
[Coming soon]

### Timeline/Scoring
The competition includes 2 rounds: Round 1 (a qualifying round) and Round 2 (the final round). Round 1 began in May 2017, with submissions for that round accepted until mid-October. At the Round 1/October 2017 deadline, teams contributed final updates to predictive models, the leaderboard locked, and scoring commenced. Teams that finish in the top 100 will continue on to Round 2 in January 2018. From there, competitors will have the opportunity to enhance pre-existing models accordingly.

There are two leaderboards: 1 public and 1 private. To uphold the integrity of the competition, the public leaderboard is scored on a different set of data than that of the private leaderboard. Kaggle may also temporarily swap the leaderboard display between the public and private versions. This, and a variety of other factors (such as team disqualification), may temporarily alter the publicly displayed rankings and participating number of teams.


### Results and Code Availability
Competition scoring is currently ongoing, with 3,700+ teams (initially 3,800+) competing for $1.2 million in prizes. Due to the nature of the project, code and strategy cannot be publicly released at this time. In the meantime, I'm glad to discuss project details, data and tools used, and aspects of my process and approach. I'm presently in the top 0.6%.


## About Files/Folders in this Repository
* EDA folder: The images within the Exploratory Data Analysis (EDA) folder were created using Jupyter Notebook. These graphs help viewers understand types of data, how much data was used, and how that data is useful.
* [Coming Soon]


## Installation
The installation documentation for the Jupyter platform can be found [here](https://jupyter.readthedocs.io/en/latest/install.html).

Documentation for advanced usage of Jupyter notebook can be found [here](https://jupyter-notebook.readthedocs.io/en/latest/).
 
 
This project requires **Python 3.6** and the following Python libraries installed:
* [NumPy](http://www.numpy.org/)
* [Pandas](http://pandas.pydata.org)
* [openpyxl](http://openpyxl.readthedocs.io/en/default/index.html)
* [folium](https://folium.readthedocs.io/en/latest/)
* [scikit-learn](http://scikit-learn.org/stable/)
* [matplotlib](http://matplotlib.org/)
* [seaborn](https://seaborn.pydata.org/)


To run locally on your machine, launch with:
 
     $ jupyter notebook
     
     
